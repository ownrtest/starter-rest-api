{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXUHUdUsddee"
      },
      "source": [
        "# Fish Speech"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y5IgX9tddee"
      },
      "source": [
        "### For Windows User / win用户"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "bat"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ndMQlQcddef",
        "outputId": "6a928183-62c8-4c0d-c285-830a3e2d1fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'fish-speech' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/fishaudio/fish-speech.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnjq3NFKddef"
      },
      "source": [
        "### For Linux User / Linux 用户"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 更改工作目录\n",
        "os.chdir('/content/fish-speech')\n",
        "\n",
        "# 检查当前工作目录\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCr-dX12d8-O",
        "outputId": "5d1ce68b-371e-46f9-b082-a16e6a77b4ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fish-speech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe42NYkXe3QI",
        "outputId": "a2878b52-fb6a-42d5-ed8e-5c8a6f16526b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.1\n",
            "  Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchvision==0.19.1\n",
            "  Downloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting torchaudio==2.4.1\n",
            "  Downloading torchaudio-2.4.1-cp311-cp311-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.1) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.1)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.1)\n",
            "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.1) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.1) (11.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.1) (1.3.0)\n",
            "Downloading torch-2.4.1-cp311-cp311-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.19.1-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.4.1-cp311-cp311-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu124\n",
            "    Uninstalling torchaudio-2.5.1+cu124:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu124\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.1 torchaudio-2.4.1 torchvision-0.19.1 triton-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libsox-dev ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHA7iythe7or",
        "outputId": "570caa02-0d66-4183-f0b2-b31d63dd6019"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-all\n",
            "  libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base libsox-fmt-mp3 libsox-fmt-oss libsox-fmt-pulse\n",
            "  libsox3 libwavpack1\n",
            "Suggested packages:\n",
            "  libaudio2 libsndio6.1\n",
            "The following NEW packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0 libsox-dev\n",
            "  libsox-fmt-all libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base libsox-fmt-mp3 libsox-fmt-oss\n",
            "  libsox-fmt-pulse libsox3 libwavpack1\n",
            "0 upgraded, 16 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 1,053 kB of archives.\n",
            "After this operation, 4,061 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao-common all 1.2.2+20180113-1.1ubuntu3 [6,568 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao4 amd64 1.2.2+20180113-1.1ubuntu3 [35.2 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libid3tag0 amd64 0.15.1b-14 [31.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmad0 amd64 0.15.1b-10ubuntu1 [63.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [240 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [11.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-ao amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,740 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [33.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-mp3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [17.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-oss amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [9,424 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-pulse amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,732 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-all amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [5,016 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-dev amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [356 kB]\n",
            "Fetched 1,053 kB in 1s (787 kB/s)\n",
            "Selecting previously unselected package libao-common.\n",
            "(Reading database ... 124947 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libao-common_1.2.2+20180113-1.1ubuntu3_all.deb ...\n",
            "Unpacking libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libao4:amd64.\n",
            "Preparing to unpack .../01-libao4_1.2.2+20180113-1.1ubuntu3_amd64.deb ...\n",
            "Unpacking libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libid3tag0:amd64.\n",
            "Preparing to unpack .../02-libid3tag0_0.15.1b-14_amd64.deb ...\n",
            "Unpacking libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Selecting previously unselected package libmad0:amd64.\n",
            "Preparing to unpack .../03-libmad0_0.15.1b-10ubuntu1_amd64.deb ...\n",
            "Unpacking libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "Preparing to unpack .../04-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../05-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../06-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../07-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-ao:amd64.\n",
            "Preparing to unpack .../08-libsox-fmt-ao_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwavpack1:amd64.\n",
            "Preparing to unpack .../09-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
            "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../10-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-mp3:amd64.\n",
            "Preparing to unpack .../11-libsox-fmt-mp3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-oss:amd64.\n",
            "Preparing to unpack .../12-libsox-fmt-oss_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-pulse:amd64.\n",
            "Preparing to unpack .../13-libsox-fmt-pulse_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-all:amd64.\n",
            "Preparing to unpack .../14-libsox-fmt-all_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-dev:amd64.\n",
            "Preparing to unpack .../15-libsox-dev_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install build-essential \\\n",
        "    cmake \\\n",
        "    libasound-dev \\\n",
        "    portaudio19-dev \\\n",
        "    libportaudio2 \\\n",
        "    libportaudiocpp0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-GRtc8xfCUw",
        "outputId": "fc42f3de-9da3-43eb-f633-f9b91f585d7d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'libasound2-dev' instead of 'libasound-dev'\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "libasound2-dev is already the newest version (1.2.6.1-1ubuntu1).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "Suggested packages:\n",
            "  portaudio19-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0 portaudio19-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 188 kB of archives.\n",
            "After this operation, 927 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
            "Fetched 188 kB in 1s (335 kB/s)\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 125096 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-MzkWTyfHdn",
        "outputId": "93cfbe85-ed70-499f-a3ca-ea77361d73a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fish-speech\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<=1.26.4 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: transformers>=4.45.2 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (4.48.3)\n",
            "Requirement already satisfied: datasets==2.18.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (2.18.0)\n",
            "Requirement already satisfied: lightning>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (2.5.0.post0)\n",
            "Requirement already satisfied: hydra-core>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.3.2)\n",
            "Requirement already satisfied: tensorboard>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (2.18.0)\n",
            "Requirement already satisfied: natsort>=8.4.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (8.4.0)\n",
            "Requirement already satisfied: einops>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.8.1)\n",
            "Requirement already satisfied: librosa>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.10.2.post1)\n",
            "Requirement already satisfied: rich>=13.5.3 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (13.9.4)\n",
            "Requirement already satisfied: gradio>5.0.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (5.20.0)\n",
            "Requirement already satisfied: wandb>=0.15.11 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.19.7)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.70.0)\n",
            "Requirement already satisfied: kui>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.8.1)\n",
            "Requirement already satisfied: uvicorn>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.34.0)\n",
            "Requirement already satisfied: loguru>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.7.3)\n",
            "Requirement already satisfied: loralib>=0.1.2 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: pyrootutils>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.0.4)\n",
            "Requirement already satisfied: vector_quantize_pytorch==1.14.24 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.14.24)\n",
            "Requirement already satisfied: resampy>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.4.3)\n",
            "Requirement already satisfied: einx==0.2.2 in /usr/local/lib/python3.11/dist-packages (from einx[torch]==0.2.2->fish-speech==0.1.0) (0.2.2)\n",
            "Requirement already satisfied: zstandard>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.23.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.25.1)\n",
            "Requirement already satisfied: pyaudio in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.2.14)\n",
            "Requirement already satisfied: faster_whisper in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.1.1)\n",
            "Requirement already satisfied: modelscope==1.17.1 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.17.1)\n",
            "Requirement already satisfied: funasr==1.1.5 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.1.5)\n",
            "Requirement already satisfied: opencc-python-reimplemented==0.1.7 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.1.7)\n",
            "Requirement already satisfied: silero-vad in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (5.1.2)\n",
            "Requirement already satisfied: ormsgpack in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: tiktoken>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (0.9.0)\n",
            "Requirement already satisfied: pydantic==2.9.2 in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (2.9.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from fish-speech==0.1.0) (5.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->fish-speech==0.1.0) (2024.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.18.0->fish-speech==0.1.0) (6.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (from einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (2.4.6)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from einx[torch]==0.2.2->fish-speech==0.1.0) (2.4.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (1.13.1)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.13.1)\n",
            "Requirement already satisfied: kaldiio>=2.17.0 in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (2.18.0)\n",
            "Requirement already satisfied: torch-complex in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.4.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.42.1)\n",
            "Requirement already satisfied: pytorch-wpe in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.0.1)\n",
            "Requirement already satisfied: editdistance>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.8.1)\n",
            "Requirement already satisfied: oss2 in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (2.19.1)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.5.7)\n",
            "Requirement already satisfied: jaconv in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.11/dist-packages (from funasr==1.1.5->fish-speech==0.1.0) (2.6.2.2)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.11/dist-packages (from modelscope==1.17.1->fish-speech==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.9.2->fish-speech==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.115.11)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.2 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (1.7.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (3.10.15)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (11.1.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.9.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.46.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio>5.0.0->fish-speech==0.1.0) (0.15.1)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio>5.0.0->fish-speech==0.1.0) (14.2)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->fish-speech==0.1.0) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.3.2->fish-speech==0.1.0) (4.9.3)\n",
            "Requirement already satisfied: baize>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from kui>=1.6.0->fish-speech==0.1.0) (0.22.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.61.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.1->fish-speech==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.1.0->fish-speech==0.1.0) (0.13.1)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning>=2.1.0->fish-speech==0.1.0) (1.6.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning>=2.1.0->fish-speech==0.1.0) (2.5.0.post0)\n",
            "Requirement already satisfied: python-dotenv>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from pyrootutils>=1.0.4->fish-speech==0.1.0) (1.0.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.5.3->fish-speech==0.1.0) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.14.1->fish-speech==0.1.0) (3.1.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.8.0->fish-speech==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45.2->fish-speech==0.1.0) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45.2->fish-speech==0.1.0) (0.5.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.30.0->fish-speech==0.1.0) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.30.0->fish-speech==0.1.0) (0.14.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (4.3.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.11->fish-speech==0.1.0) (1.3.5)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.11/dist-packages (from faster_whisper->fish-speech==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from faster_whisper->fish-speech==0.1.0) (1.20.1)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.11/dist-packages (from faster_whisper->fish-speech==0.1.0) (14.2.0)\n",
            "Requirement already satisfied: torchaudio>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from silero-vad->fish-speech==0.1.0) (2.4.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio>5.0.0->fish-speech==0.1.0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio>5.0.0->fish-speech==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.18.0->fish-speech==0.1.0) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio>5.0.0->fish-speech==0.1.0) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio>5.0.0->fish-speech==0.1.0) (1.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.3->fish-speech==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa>=0.10.1->fish-speech==0.1.0) (0.44.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster_whisper->fish-speech==0.1.0) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster_whisper->fish-speech==0.1.0) (25.2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.18.0->fish-speech==0.1.0) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets==2.18.0->fish-speech==0.1.0) (3.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa>=0.10.1->fish-speech==0.1.0) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->funasr==1.1.5->fish-speech==0.1.0) (1.17.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->einx[torch]==0.2.2->fish-speech==0.1.0) (12.5.82)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio>5.0.0->fish-speech==0.1.0) (1.5.4)\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.11/dist-packages (from oss2->funasr==1.1.5->fish-speech==0.1.0) (1.7)\n",
            "Requirement already satisfied: pycryptodome>=3.4.7 in /usr/local/lib/python3.11/dist-packages (from oss2->funasr==1.1.5->fish-speech==0.1.0) (3.21.0)\n",
            "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from oss2->funasr==1.1.5->fish-speech==0.1.0) (2.16.5)\n",
            "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /usr/local/lib/python3.11/dist-packages (from oss2->funasr==1.1.5->fish-speech==0.1.0) (2.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->einx==0.2.2->einx[torch]==0.2.2->fish-speech==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn->funasr==1.1.5->fish-speech==0.1.0) (0.5.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.1.5->fish-speech==0.1.0) (0.10.0)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.1.5->fish-speech==0.1.0) (43.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->funasr==1.1.5->fish-speech==0.1.0) (2.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.11->fish-speech==0.1.0) (5.0.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster_whisper->fish-speech==0.1.0) (10.0)\n",
            "Building wheels for collected packages: fish-speech\n",
            "  Building editable for fish-speech (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fish-speech: filename=fish_speech-0.1.0-0.editable-py3-none-any.whl size=10341 sha256=8e14141f11b580208ccb38b2b33f1b1d9a08bca6ddcc181c0e28b25a0d8ef66b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9t0o7ssg/wheels/1d/8d/79/64aa115a26c1628f19c01f0b6214e49c83c75365353fa810b5\n",
            "Successfully built fish-speech\n",
            "Installing collected packages: fish-speech\n",
            "  Attempting uninstall: fish-speech\n",
            "    Found existing installation: fish-speech 0.1.0\n",
            "    Uninstalling fish-speech-0.1.0:\n",
            "      Successfully uninstalled fish-speech-0.1.0\n",
            "Successfully installed fish-speech-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4NGqj8VKddef",
        "outputId": "f6059058-880f-4ca7-b7d3-59f3de7e4f95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'en_US.UTF-8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import locale\n",
        "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfV_Jt6iddeg"
      },
      "source": [
        "### Prepare Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-NpQ8fUddeg",
        "outputId": "a83bea75-7aca-4d9f-89ff-34b74917a0c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rFetching 7 files:   0% 0/7 [00:00<?, ?it/s]Downloading 'special_tokens.json' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/Pdr1pnDFqf3r8xSTD-lPnaCpeRA=.db54e3cccbbaa1106ba8d56e810dffd42e325ab0.incomplete'\n",
            "Downloading 'model.pth' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/YT0Y2lJH9mHYafdr2d9j82hXvzY=.918dc960372cc1b77bbafb14c48ef7a1634ecf75d4eb85b78607223b780d6001.incomplete'\n",
            "Downloading '.gitattributes' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
            "Downloading 'config.json' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.3f8edf91f7a0b152e5f8c30fd412c5d7e22020b5.incomplete'\n",
            "Downloading 'tokenizer.tiktoken' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/zENsYUfT6EG2Nj68LEJ8oOfAxB8=.21dcfcb37df8da533b2d4fe0b867472f04cda62e.incomplete'\n",
            "Downloading 'README.md' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.a43b65346beef6fa83135bd1dff857a00b6a9c13.incomplete'\n",
            "\n",
            "special_tokens.json: 100% 31.0k/31.0k [00:00<00:00, 4.70MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/special_tokens.json\n",
            "\n",
            "config.json: 100% 697/697 [00:00<00:00, 4.93MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/config.json\n",
            "\n",
            "tokenizer.tiktoken:   0% 0.00/1.70M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            ".gitattributes: 100% 1.52k/1.52k [00:00<00:00, 15.7MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/.gitattributes\n",
            "Fetching 7 files:  14% 1/7 [00:00<00:01,  4.47it/s]Downloading 'firefly-gan-vq-fsq-8x1024-21hz-generator.pth' to 'checkpoints/fish-speech-1.5/.cache/huggingface/download/Khmizewsuzbxb3XfvhhbrTGaoLE=.01b81dbf753224a156c3fe139b88bf0b9a0f54b11bee864f95e66511c3ccd754.incomplete'\n",
            "\n",
            "\n",
            "model.pth:   0% 0.00/1.28G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "README.md: 100% 1.68k/1.68k [00:00<00:00, 18.5MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/README.md\n",
            "\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:   0% 0.00/189M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:   1% 10.5M/1.28G [00:00<00:15, 80.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:   6% 10.5M/189M [00:00<00:02, 66.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "tokenizer.tiktoken: 100% 1.70M/1.70M [00:00<00:00, 8.12MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/tokenizer.tiktoken\n",
            "\n",
            "\n",
            "model.pth:   2% 31.5M/1.28G [00:00<00:10, 119MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  11% 21.0M/189M [00:00<00:02, 70.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:   5% 62.9M/1.28G [00:00<00:06, 182MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  17% 31.5M/189M [00:00<00:02, 70.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:   7% 83.9M/1.28G [00:00<00:06, 188MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  22% 41.9M/189M [00:00<00:02, 72.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:   8% 105M/1.28G [00:00<00:07, 162MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  28% 52.4M/189M [00:00<00:01, 73.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  10% 126M/1.28G [00:00<00:07, 156MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  33% 62.9M/189M [00:00<00:01, 75.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  12% 147M/1.28G [00:00<00:07, 153MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  39% 73.4M/189M [00:00<00:01, 76.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  13% 168M/1.28G [00:01<00:07, 155MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  44% 83.9M/189M [00:01<00:01, 78.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  15% 189M/1.28G [00:01<00:07, 155MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  50% 94.4M/189M [00:01<00:01, 78.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  16% 210M/1.28G [00:01<00:07, 151MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  56% 105M/189M [00:01<00:01, 76.8MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  18% 231M/1.28G [00:01<00:06, 159MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  61% 115M/189M [00:01<00:00, 76.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  20% 252M/1.28G [00:01<00:06, 165MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  67% 126M/189M [00:01<00:00, 77.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  21% 273M/1.28G [00:01<00:06, 162MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  72% 136M/189M [00:01<00:00, 74.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  24% 304M/1.28G [00:01<00:05, 164MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  78% 147M/189M [00:01<00:00, 77.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  25% 325M/1.28G [00:02<00:05, 172MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  83% 157M/189M [00:02<00:00, 77.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  27% 346M/1.28G [00:02<00:05, 174MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  89% 168M/189M [00:02<00:00, 77.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  30% 377M/1.28G [00:02<00:04, 185MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth:  95% 178M/189M [00:02<00:00, 77.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  31% 398M/1.28G [00:02<00:05, 171MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)fly-gan-vq-fsq-8x1024-21hz-generator.pth: 100% 189M/189M [00:02<00:00, 75.2MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\n",
            "Fetching 7 files:  57% 4/7 [00:02<00:02,  1.36it/s]\n",
            "\n",
            "model.pth:  33% 419M/1.28G [00:02<00:04, 172MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  35% 451M/1.28G [00:02<00:04, 200MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  38% 482M/1.28G [00:02<00:03, 216MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  40% 514M/1.28G [00:02<00:03, 213MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  43% 545M/1.28G [00:03<00:03, 218MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  45% 577M/1.28G [00:03<00:03, 217MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  48% 608M/1.28G [00:03<00:03, 221MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  50% 640M/1.28G [00:03<00:02, 219MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  53% 671M/1.28G [00:03<00:02, 211MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  55% 703M/1.28G [00:03<00:02, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  58% 734M/1.28G [00:03<00:02, 220MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  60% 765M/1.28G [00:04<00:02, 212MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  62% 797M/1.28G [00:06<00:11, 41.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  65% 828M/1.28G [00:06<00:07, 56.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  67% 860M/1.28G [00:06<00:05, 73.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  69% 881M/1.28G [00:06<00:04, 85.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  71% 912M/1.28G [00:06<00:03, 107MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.pth:  74% 944M/1.28G [00:06<00:02, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  76% 975M/1.28G [00:07<00:02, 146MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  79% 1.01G/1.28G [00:07<00:01, 155MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  81% 1.04G/1.28G [00:07<00:01, 171MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  84% 1.07G/1.28G [00:07<00:01, 188MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  86% 1.10G/1.28G [00:07<00:00, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  89% 1.13G/1.28G [00:07<00:00, 199MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  91% 1.16G/1.28G [00:07<00:00, 196MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  94% 1.20G/1.28G [00:08<00:00, 201MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth:  96% 1.23G/1.28G [00:08<00:00, 205MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.pth: 100% 1.28G/1.28G [00:08<00:00, 151MB/s]\n",
            "Download complete. Moving file to checkpoints/fish-speech-1.5/model.pth\n",
            "Fetching 7 files: 100% 7/7 [00:08<00:00,  1.25s/it]\n",
            "/content/checkpoints/fish-speech-1.5\n"
          ]
        }
      ],
      "source": [
        "# For Chinese users, you probably want to use mirror to accelerate downloading\n",
        "# !set HF_ENDPOINT=https://hf-mirror.com\n",
        "# !export HF_ENDPOINT=https://hf-mirror.com\n",
        "\n",
        "!huggingface-cli download fishaudio/fish-speech-1.5 --local-dir checkpoints/fish-speech-1.5/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XGLChtsddeg"
      },
      "source": [
        "## WebUI Inference\n",
        "\n",
        "> You can use --compile to fuse CUDA kernels for faster inference (10x)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu8rKLQKddeh",
        "outputId": "bfb48d24-7baf-4cd3-af12-39b72f2e22fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2025-03-05 04:42:51.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mLoading Llama model...\u001b[0m\n",
            "\u001b[32m2025-03-05 04:43:04.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m681\u001b[0m - \u001b[1mRestored model from checkpoint\u001b[0m\n",
            "\u001b[32m2025-03-05 04:43:04.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m687\u001b[0m - \u001b[1mUsing DualARTransformer\u001b[0m\n",
            "\u001b[32m2025-03-05 04:43:04.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m695\u001b[0m - \u001b[1mCompiling function...\u001b[0m\n",
            "\u001b[32m2025-03-05 04:43:05.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mLoading VQ-GAN model...\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:445: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:630: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/finite_scalar_quantization.py:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/lookup_free_quantization.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  @autocast(enabled = False)\n",
            "\u001b[32m2025-03-05 04:43:08.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.vqgan.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mLoaded model: <All keys matched successfully>\u001b[0m\n",
            "\u001b[32m2025-03-05 04:43:08.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mDecoder model loaded, warming up...\u001b[0m\n",
            "\u001b[32m2025-03-05 04:43:08.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: Hello world.\u001b[0m\n",
            "\u001b[32m2025-03-05 04:43:08.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 1/1 of sample 1/1\u001b[0m\n",
            "  0% 0/1023 [00:00<?, ?it/s]/usr/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "W0305 04:44:58.846000 133912790808128 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n",
            "  0% 1/1023 [04:49<82:11:39, 289.53s/it]/usr/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "  0% 2/1023 [04:50<33:59:24, 119.85s/it]/usr/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "  2% 19/1023 [04:50<4:16:07, 15.31s/it]\n",
            "\u001b[32m2025-03-05 04:48:00.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m851\u001b[0m - \u001b[1mCompilation time: 291.44 seconds\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:00.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 21 tokens in 291.44 seconds, 0.07 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:00.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 0.05 GB/s\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:00.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 2.22 GB\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:00.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 20])\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:02.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m98\u001b[0m - \u001b[1mWarming up done, launching the web UI...\u001b[0m\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://92efef341e737c722b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "\u001b[32m2025-03-05 04:48:24.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: 臣司马光曰：\n",
            "　　我知道天子的职责中最重要的是维护礼教，礼教中最重要的是区分地位，区分地位中最重要的是匡正名分。什么是礼教？就是法纪。\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:24.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: 什么是区分地位？就是君臣有别。什么是名分？就是公、侯、卿、大夫等官爵。\n",
            "　　四海之广，亿民之众，都受制于天子一人。\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:24.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: 尽管是才能超群、智慧绝伦的人，也不能不在天子足下为他奔走服务，这难道不是以礼作为礼纪朝纲的作用吗！\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:24.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: 所以，天子统率三公，三公督率诸侯国君，诸侯国君节制卿、大夫官员，卿、大夫官员又统治士人百姓。权贵支配贱民，贱民服从权贵。\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:24.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: 上层指挥下层就好像人的心腹控制四肢行动，树木的根和干支配枝和叶；下层服侍上层就好像人的四肢卫护心腹，树木的枝和叶遮护根和干，\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:24.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: 这样才能上下层互相保护，从而使国家得到长治久安。所以说，天子的职责没有比维护礼制更重要的了。\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:24.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 1/6 of sample 1/1\u001b[0m\n",
            "  0% 0/8129 [00:00<?, ?it/s]/usr/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
            "  self.gen = func(*args, **kwds)\n",
            "  4% 339/8129 [00:04<01:33, 83.45it/s]\n",
            "\u001b[32m2025-03-05 04:48:28.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m851\u001b[0m - \u001b[1mCompilation time: 4.20 seconds\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:28.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 341 tokens in 4.20 seconds, 81.16 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:28.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 51.77 GB/s\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:28.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 2.26 GB\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:28.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 2/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:28.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 340])\u001b[0m\n",
            "  4% 283/7735 [00:03<01:31, 81.75it/s]\n",
            "\u001b[32m2025-03-05 04:48:32.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 285 tokens in 3.72 seconds, 76.64 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:32.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 48.89 GB/s\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:32.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 2.63 GB\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:32.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 3/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:32.242\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 284])\u001b[0m\n",
            "  3% 204/7408 [00:02<01:27, 81.90it/s]\n",
            "\u001b[32m2025-03-05 04:48:35.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 206 tokens in 2.77 seconds, 74.32 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:35.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 47.41 GB/s\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:35.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 2.63 GB\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:35.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 4/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:35.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 205])\u001b[0m\n",
            "  4% 295/7148 [00:03<01:24, 81.55it/s]\n",
            "\u001b[32m2025-03-05 04:48:38.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 297 tokens in 3.94 seconds, 75.44 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:38.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 48.13 GB/s\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:38.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 2.63 GB\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:38.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 5/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:38.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 296])\u001b[0m\n",
            "  4% 300/6799 [00:03<01:16, 84.55it/s]\n",
            "\u001b[32m2025-03-05 04:48:42.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 302 tokens in 4.00 seconds, 75.48 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:42.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 48.15 GB/s\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:42.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 2.63 GB\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:42.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 6/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:42.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 301])\u001b[0m\n",
            "  3% 193/6460 [00:02<01:14, 84.10it/s]\n",
            "\u001b[32m2025-03-05 04:48:45.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 195 tokens in 2.80 seconds, 69.56 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:45.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 44.38 GB/s\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:45.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 2.63 GB\u001b[0m\n",
            "\u001b[32m2025-03-05 04:48:45.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 194])\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/processing_utils.py:749: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "\u001b[32m2025-03-05 04:59:20.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mLoaded audio with 19.54 seconds\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/vector_quantize_pytorch/residual_fsq.py:170: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(enabled = False):\n",
            "\u001b[32m2025-03-05 04:59:21.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mEncoded prompt: torch.Size([8, 421])\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:21.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: 臣司马光曰：\n",
            "　　我知道天子的职责中最重要的是维护礼教，礼教中最重要的是区分地位，区分地位中最重要的是匡正名分。什么是礼教？就是法纪。\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:21.158\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: 什么是区分地位？就是君臣有别。什么是名分？就是公、侯、卿、大夫等官爵。\n",
            "　　四海之广，亿民之众，都受制于天子一人。\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:21.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: 尽管是才能超群、智慧绝伦的人，也不能不在天子足下为他奔走服务，这难道不是以礼作为礼纪朝纲的作用吗！\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:21.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: 所以，天子统率三公，三公督率诸侯国君，诸侯国君节制卿、大夫官员，卿、大夫官员又统治士人百姓。权贵支配贱民，贱民服从权贵。\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:21.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: 上层指挥下层就好像人的心腹控制四肢行动，树木的根和干支配枝和叶；下层服侍上层就好像人的四肢卫护心腹，树木的枝和叶遮护根和干，\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:21.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: 这样才能上下层互相保护，从而使国家得到长治久安。所以说，天子的职责没有比维护礼制更重要的了。\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:21.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 1/6 of sample 1/1\u001b[0m\n",
            "  4% 343/7698 [00:04<01:26, 84.76it/s]\n",
            "\u001b[32m2025-03-05 04:59:25.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m851\u001b[0m - \u001b[1mCompilation time: 4.28 seconds\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:25.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 345 tokens in 4.28 seconds, 80.69 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:25.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 51.47 GB/s\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:25.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 2.63 GB\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:25.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 2/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:25.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 344])\u001b[0m\n",
            "  9% 664/7300 [00:07<01:18, 84.92it/s]\n",
            "\u001b[32m2025-03-05 04:59:33.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 666 tokens in 8.24 seconds, 80.85 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:33.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 51.57 GB/s\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:33.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 2.67 GB\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:33.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 3/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-03-05 04:59:33.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 665])\u001b[0m\n",
            "100% 6592/6592 [01:18<00:00, 83.80it/s]\n",
            "\u001b[32m2025-03-05 05:00:53.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 6593 tokens in 79.38 seconds, 83.05 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-03-05 05:00:53.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 52.98 GB/s\u001b[0m\n",
            "\u001b[32m2025-03-05 05:00:53.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 3.07 GB\u001b[0m\n",
            "\u001b[32m2025-03-05 05:00:53.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 4/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-03-05 05:00:53.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 6592])\u001b[0m\n",
            "  5% 354/7299 [00:04<01:23, 83.05it/s]\n",
            "\u001b[32m2025-03-05 05:01:01.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 356 tokens in 8.85 seconds, 40.24 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-03-05 05:01:01.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 25.67 GB/s\u001b[0m\n",
            "\u001b[32m2025-03-05 05:01:01.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 10.16 GB\u001b[0m\n",
            "\u001b[32m2025-03-05 05:01:01.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 5/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-03-05 05:01:01.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 355])\u001b[0m\n",
            "  5% 365/6891 [00:04<01:18, 82.93it/s]\n",
            "\u001b[32m2025-03-05 05:01:06.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 367 tokens in 4.91 seconds, 74.82 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-03-05 05:01:06.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 47.73 GB/s\u001b[0m\n",
            "\u001b[32m2025-03-05 05:01:06.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 10.16 GB\u001b[0m\n",
            "\u001b[32m2025-03-05 05:01:06.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 6/6 of sample 1/1\u001b[0m\n",
            "\u001b[32m2025-03-05 05:01:06.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 366])\u001b[0m\n",
            "  4% 236/6487 [00:02<01:16, 81.43it/s]\n",
            "\u001b[32m2025-03-05 05:01:10.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 238 tokens in 3.47 seconds, 68.52 tokens/sec\u001b[0m\n",
            "\u001b[32m2025-03-05 05:01:10.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 43.71 GB/s\u001b[0m\n",
            "\u001b[32m2025-03-05 05:01:10.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 10.16 GB\u001b[0m\n",
            "\u001b[32m2025-03-05 05:01:10.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mdecode_vq_tokens\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mVQ features: torch.Size([8, 237])\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python tools/run_webui.py \\\n",
        "    --llama-checkpoint-path checkpoints/fish-speech-1.5 \\\n",
        "    --decoder-checkpoint-path checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth \\\n",
        "    --compile \\\n",
        "    --half"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mixdas4Lddeh"
      },
      "source": [
        "## Break-down CLI Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhIOxKFCddeh"
      },
      "source": [
        "### 1. Encode reference audio: / 从语音生成 prompt:\n",
        "\n",
        "You should get a `fake.npy` file.\n",
        "\n",
        "你应该能得到一个 `fake.npy` 文件."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "YRsv7j7wddeh"
      },
      "outputs": [],
      "source": [
        "## Enter the path to the audio file here\n",
        "src_audio = r\"D:\\PythonProject\\vo_hutao_draw_appear.wav\"\n",
        "\n",
        "!python fish_speech/models/vqgan/inference.py \\\n",
        "    -i {src_audio} \\\n",
        "    --checkpoint-path \"checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "audio = Audio(filename=\"fake.wav\")\n",
        "display(audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1mXDYHnddeh"
      },
      "source": [
        "### 2. Generate semantic tokens from text: / 从文本生成语义 token:\n",
        "\n",
        "> This command will create a codes_N file in the working directory, where N is an integer starting from 0.\n",
        "\n",
        "> You may want to use `--compile` to fuse CUDA kernels for faster inference (~30 tokens/second -> ~300 tokens/second).\n",
        "\n",
        "> 该命令会在工作目录下创建 codes_N 文件, 其中 N 是从 0 开始的整数.\n",
        "\n",
        "> 您可以使用 `--compile` 来融合 cuda 内核以实现更快的推理 (~30 tokens/秒 -> ~300 tokens/秒)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "yrBLXcN6ddei"
      },
      "outputs": [],
      "source": [
        "!python fish_speech/models/text2semantic/inference.py \\\n",
        "    --text \"hello world\" \\\n",
        "    --prompt-text \"The text corresponding to reference audio\" \\\n",
        "    --prompt-tokens \"fake.npy\" \\\n",
        "    --checkpoint-path \"checkpoints/fish-speech-1.5\" \\\n",
        "    --num-samples 2\n",
        "    # --compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCOht-y_ddei"
      },
      "source": [
        "### 3. Generate speech from semantic tokens: / 从语义 token 生成人声:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "a-7e6AiQddei"
      },
      "outputs": [],
      "source": [
        "!python fish_speech/models/vqgan/inference.py \\\n",
        "    -i \"codes_0.npy\" \\\n",
        "    --checkpoint-path \"checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\"\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "audio = Audio(filename=\"fake.wav\")\n",
        "display(audio)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}